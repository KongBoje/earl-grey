
require:
   "./location" ->
      Location, [<<:]

provide:
   tokenize
   process_indent
   disambiguate_fixity
   alternate_operators
   fill_locations
   unescape



unescape{s} =
   repl = {
      b = String.fromCharCode{8}
      f = String.fromCharCode{12}
      n = "\n"
      r = String.fromCharCode{13}
      t = String.fromCharCode{9}
   }
   s.replace{rx, f} where
      rx = R.g"\\u[0-9A-Fa-f]{4}|\\x[0-9A-Fa-f]{2}|\\."
      f{match} =
         R"^(?:\\u|\\x)(.*)"! {_, digits} ->
            String.fromCharCode{parseInt{digits, 16}}
         R"^.(.)"! {_, chr} ->
            repl[chr] or chr


special_ops = {
   ;; Operators for which the fixity is predetermined regardless
   ;; of whitespace or other factors.
   "(" => .PFX
   "[" => .PFX
   "{" => .PFX
   ")" => .SFX
   "]" => .SFX
   "}" => .SFX
   "," => .IFX
   ";" => .IFX
   ;; ":" => .IFX
   "." => .PFX
   ;; "'" => .PFX
   "not" => .PFX
   "??" => .SFX
   ;; "?" => .IFX
   ;; "!" => .IFX
}

regexps = {
   {op3,    op_f}
   {id,     id_f}
   {numr,   numr_f}
   {num,    num_f}
   {str2,   str_f}
   {str,    str_f}
   {quasi2, quasi_f}
   {quasi,  quasi_f}
   {quaint2, quaint_f}
   {quaint,  quaint_f}
   {op,     op_f}
   {op2,    op_f}
   {indent, indent_f}
   {indent2, indent2_f}
   {cmnt,   cmnt_f}
   {op4,    op_f}
   {ign,    ign_f}
   {unkn,   unkn_f}
} where

  ;; Identifiers
  ;; ex. abc, Abc123, _x, $, a$b$c
  id = R```
     start
     in "a-zA-Z$_" or ["\\_", any]
     * [in "a-zA-Z$_0-9" or ["\\_", any] or ["-", in "a-zA-Z$_0-9"]]
  ```

  id_f = {m} ->
     #ID{m[0].replace{R.g"\\_(.)", {_, x} -> x}}


  ;; Numbers with arbitrary radii
  ;; ex. 2r1110, 36rZ, 4r312.33
  numr = R```
     start
     {+d}, in "rR"
     {+ in"A-Za-z0-9_"}
     ?[".", {+ in "A-Za-z0-9_"}]
  ```

  numr_f = {m} ->
     {_, radix, intp, frac} = m
     var value = parseInt{intp.replace{R.g"_", ""}, radix}
     if frac:
        let [frac = frac.replace{R.g"_", ""}]:
           value = value + parseInt{frac, radix} / Math.pow{radix, frac.length}
     #NUM{value}


  ;; Base 10 numbers
  num = R```
     start
     {+ in "0-9_"}
     ?[".", {+d}]
     ?[in "eE", {? in "+-", + in "0-9_"}]
  ```

  num_f = {m} ->
     #NUM{parseFloat{m[0].replace{R.g"_", ""}}}


  ;; ;; Strings (no interpolation)
  ;; str = R'
  ;;    start
  ;;    "\""
  ;;    {*["\\\\" or "\\\"" or [not in "\""]]}
  ;;    "\""

  ;; str_f = {m} ->
  ;;    repl = {
  ;;       "\\\"" => "\""
  ;;       "\\\\" => "\\"
  ;;       "\\n" => "\n"
  ;;    }
  ;;    r = m[1].replace{R.g'{"\\\"" or "\\\\" or "\\n"}, {m} -> repl[m]}
  ;;    #STR{r}

  ;; Quasiquote
  quasi = R```
     start
     "`"
     {*[["\\", any] or [not in "`"]]}
     "`"
  ```

  quasi2 = R"^[`]{3,}((?:[\\.]|[^`]|``?[^`])*)[`]{3,}"

  quasi_f = {m} ->
     #QUASI{m[1]}


  ;; Quaint
  quaint = R```
     start
     "'"
     {*[["\\", any] or [not in "'"]]}
     "'"
  ```

  quaint2 = R"^[']{3,}((?:[\\.]|[^']|''?[^'])*)[']{3,}"

  quaint_f = {m} ->
     #QUAINT{m[1]}



  ;; Strings (no interpolation)
  str = R```
     start
     "\""
     {*[["\\", any] or [not in "\""]]}
     "\""
  ```

  ;; Strings (no interpolation)
  str2 = R"^[\"]{3,}((?:[\\.]|[^\"]|\"\"?[^\"])*)[\"]{3,}"

  str_f = {m} ->
     #STR{unescape{m[1]}}


  ;; Operators
  ;; ex. +, -, **+, ^%, ...
  op = R```
     start
     + in "+\\-*/~^<>=%&|?!@#:"
  ```

  ;; brackets: [], {}, ()
  op2 = R```
     start
     in "([{}])," or +"."
  ```

  ;; Word operators: with, each, each?, where%+%, etc.
  op3 = R```
     start
     "with" or "where" or "when"
       \ or "and" or "not" or "or"
       \ or "in" or "mod"
       \ or "each" or "as"
       \ or "of" or "is"
     [+ in "+*/~^<>=%&|?!@#.:"] or boundary
     raw "(?!-)"
  ```

  ;; ;; `operator`
  ;; op4 = R'
  ;;    start
  ;;    "`", {+ in "A-Za-z0-9_$"}, "`"

  op_f = {m, column} ->
     let op = m[1] or m[0]

     match:
        when op === "|" ->
           ;; | is equivalent to an indent to its column
           #INDENT{column - 1}

        when special_ops[op] ->
           ;; These operators have predetermined fixities;
           ;; Refer to special_ops before
           fixity = special_ops[op]
           #OP{fixity, op}

        otherwise ->
           #OP{"?FX", op}


  ;; Indent
  indent = R```
     start
     *["\n", *" ", ";;", * not in "\n"]
     +["\n", {*" "}]
  ```

  indent_f = {m} ->
     ilen = m[1].length
     #INDENT{ilen}


  ;; Indent 2
  indent2 = R```
     start
     "\\\\"
  ```

  indent2_f = {m, column} ->
     #INDENT{column - 2}
     

  ;; Comment
  cmnt = R```
     start
     ";;"
     * not in "\n"
  ```

  cmnt_f = {m} -> #IGNORE{}


  ;; semicolon
  op4 = R```
     start, ";"
  ```


  ;; ignore
  ign = R```
     "\r"
  ```

  ign_f = {m} ->
     #IGNORE{}


  ;; Anything else is an error
  unkn = R```
     start
     any or "\n" or "\r"
  ```

  unkn_f = {m} ->
     #ILLEGAL{m[0]}



;; TODO: ignore blank lines before continuation
ws_re = R`[start, *" ", *["\n", *" ", "\\ ", *" "]]`
eol_re = R`[start, *" ", ?"\r", "\n" or end]`


produce{src} =

   var text = src.text
   results = {}
   var wsb = text.match{ws_re}[0].length
   set-var text = text.slice{wsb}
   var pos = wsb
   var column = 0

   while text:
      for [i = 0, i < regexps.length, ++i]:
         {re, fn} = regexps[i]
         m = text.match{re}
         if m:
            skip = m[0].length
            endpos = pos + skip
            set-var column =
               splits = m[0].split{"\n"}
               if [splits.length > 1]:
                  then: splits[splits.length - 1].length
                  else: column + skip
            set-var text = text.slice{skip}
            wsa = text.match{ws_re}[0].length
            eol = text.match{eol_re} and true
            bwsb = wsb > 0
            bwsa = if{eol, bwsb, wsa > 0}
            token = fn{m, column}
            token.wsb = bwsb
            token.wsa = bwsa
            token.location = Location{src, pos, endpos}
            results.push with token
            set-var text = text.slice{wsa}
            column += wsa
            set-var wsb = wsa
            set-var pos = endpos + wsa
            break

   results



indent_tracker{} =
   ;; This returns a function that tracks indentation levels
   ;; as tokens are fed into it. For each token it returns a
   ;; list of tokens including additional commas and brackets
   ;; corresponding to line breaks, indent and dedents.

   var curr = 0          ;; current indent
   var stack = {}        ;; stack of indent levels up to this point
   var stacks = {stack}  ;; [ or { start a new stack of indent levels

   ;; We return the following function
   {match token} ->

      #INDENT{match new_indent} ->
         when [curr === false] ->
            ;; This is the first line break, we produce ";"
            set-var curr = new_indent
            {#OP{.IFX, ";"} & {wsb = true, wsa = true}}

         [> curr] ->
            ;; Indent is larger than before, so we push the previous
            ;; and produce "["
            stack.push{curr}
            set-var curr = new_indent
            {#OP{.PFX, "["} & {wsb = true, wsa = true}}

         [=== curr] ->
            ;; Same as before, ";"
            {#OP{.IFX, ";"} & {wsb = true, wsa = true}}

         [< curr] ->
            ;; Smaller than before, so we generate "]" until
            ;; the new indent is no larger than the current one
            rval = {}
            while [[stack.length > 0] and [new_indent < curr]]:
               set-var curr = stack.pop{}
               rval.push{#OP{.SFX, "]"} & {wsb = true, wsa = true}}
            rval.push{#OP{.IFX, ";"} & {wsb = true, wsa = true}}
            rval

      #ID{*stuff} -> {token}

      #OP{fixity, "[" or "{"} ->
         ;; We restart indent calculation inside each []/{} that
         ;; we find.
         stack.push{curr}
         stacks.push{stack}
         set-var stack = {}
         set-var curr = false
         {token}

      #OP{fixity, "]" or "}"} ->
         ;; We close all indented blocks with every closing bracket
         rval = stack each _ ->
            #OP{.SFX, "]"} & {wsb = true, wsa = true}
         set-var stack = stacks.pop{}
         set-var curr = stack.pop{}
         rval.push{token}
         rval

      #EOF ->
         stack each _ ->
            #OP{.SFX, "]"} & {wsb = true, wsa = true}

      other -> {token}

process_indent{stream} =
   tracker = indent_tracker{}
   var results = {}
   stream each token ->
      results ++= tracker{token}
   results ++ tracker{#EOF}


disambiguate_fixity{stream} =

   [a <<<: b] =
      a.wsb = b.wsb
      a.wsa = b.wsa
      a <<: b

   collapse_operators{buffer, *match} =
      do: n = buffer.length

      when not buffer.length ->
         {}

      {true?, true?} ->
         match buffer:
            {token and #OP{fixity, name}} ->
               {#ID{name} <<<: token}
            longer ->
               throw E.syntax.nullary{msg, {operators = buffer}} where
                  msg = "Too many consecutive operators were found here."

      {true?, _} ->
         buffer each token and #OP{_, name} ->
            #OP{.PFX, name} <<<: token

      {_, true?} ->
         buffer each token and #OP{_, name} ->
            #OP{.SFX, name} <<<: token

      _ ->
         {first and #OP{fixity, name}, *rest} = buffer
         match {first.wsb, first.wsa}:
            {false?, false?} or {true?, true?} ->
               {#OP{.IFX, name} <<<: first} ++
                  collapse_operators{rest, true, false}
            {true?, _} ->
               {#OP{.PFX, name} <<<: first} ++
                  collapse_operators{rest, true, false}
            {_, true?} ->
               let results = collapse_operators{rest, false, false}
               {t <<<: first} ++ results where t =
                  match results:
                     {} or {#OP{.PFX, *}, *} -> #OP{.IFX, name}
                     _ -> #OP{.SFX, name}

   var buffer = {}
   var pfx = true

   collapse{sfx} =
      rval = collapse_operators{buffer, pfx, sfx}
      set-var buffer = {}
      rval

   var results = {}

   stream each match token ->

      #OP{match, name} ->
         "?FX" ->
            buffer.push with token
         .IFX ->
            results ++= collapse{true}
            results.push with token
            set-var pfx = true
         .PFX ->
            results ++= collapse{false}
            results.push with token
            set-var pfx = true
         .SFX ->
            results ++= collapse{true}
            results.push with token
            set-var pfx = false

      other ->
         results ++= collapse{false}
         results.push with token
         set-var pfx = false

   results ++ collapse{true}


alternate_operators{stream} =

   W{x} = if{x, .wide, .short}

   var last_op = true
   results = {}

   stream each match token ->

      #IGNORE ->
         null

      #OP{fixity, name} ->
         if last_op:
            results.push with #VOID{}
         match fixity:
            .IFX ->
               results.push with
                  #IFX{W{token.wsa or token.wsb}, name} <<: token
               set-var last_op = true
            .PFX ->
               if [not last_op]:
                  results.push with
                     #IFX{W{token.wsb}, .WHITE}
                     #VOID{}
               results.push with
                  #PFX{W{token.wsa}, name} <<: token
               set-var last_op = true
            .SFX ->
               results.push with
                  #SFX{W{token.wsb}, name} <<: token
                  #VOID{}
               set-var last_op = false

      ;; #ILLEGAL ->
      ;;    throw E.syntax.illegal{"unknown character", {chr = token}}

      token ->
         if [not last_op]:
            results.push with
               #IFX{W{token.wsb}, .WHITE}
         results.push{token}
         set-var last_op = false

   if last_op:
      results.push with #VOID{}

   results


fill_locations{source, stream} =
   var to_fill = {}
   var start = 0
   fill{end} =
      var first = true
      to_fill each token ->
         s = if{first, [first = false, start], end}
         token.location = Location{source, s, end}
      set-var to_fill = {}
   stream each
      {=> location} when location ->
         fill{location.start}
         set-var start = location.end
      other ->
         to_fill.push with other
   fill{source.text.length}
   stream


tokenize{src} =
   chain src:
      produce{@}
      process_indent{@}
      disambiguate_fixity{@}
      alternate_operators{@}
      fill_locations{src, @}

